{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pinns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the SIR model parameters\n",
    "beta = 0.3  # Infection rate\n",
    "gamma = 0.1  # Recovery rate\n",
    "\n",
    "# Generate synthetic data for training\n",
    "def generate_data(N=1000):\n",
    "    t = np.linspace(0, 10, N)\n",
    "    S = np.exp(-beta * t)\n",
    "    I = (beta / gamma) * (1 - np.exp(-gamma * t))\n",
    "    R = 1 - S - I\n",
    "    return t, S, I, R\n",
    "\n",
    "t, S, I, R = generate_data()\n",
    "\n",
    "# Define the PINN model\n",
    "input_layer = Input(shape=(1,))\n",
    "hidden = Dense(20, activation=\"tanh\")(input_layer)\n",
    "hidden = Dense(20, activation=\"tanh\")(hidden)\n",
    "output_layer = Dense(3, activation=\"linear\")(hidden)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Define the loss function\n",
    "def pinn_loss(t, S_true, I_true, R_true):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(t)\n",
    "        outputs = model(t)\n",
    "        S_pred, I_pred, R_pred = tf.split(outputs, num_or_size_splits=3, axis=1)\n",
    "        dS_dt = tape.gradient(S_pred, t)\n",
    "        dI_dt = tape.gradient(I_pred, t)\n",
    "        dR_dt = tape.gradient(R_pred, t)\n",
    "\n",
    "    # SIR equations as constraints\n",
    "    eq1 = dS_dt + beta * S_pred * I_pred\n",
    "    eq2 = dI_dt - (beta * S_pred * I_pred - gamma * I_pred)\n",
    "    eq3 = dR_dt - gamma * I_pred\n",
    "\n",
    "    # Combine data loss and physics-based loss\n",
    "    data_loss = tf.reduce_mean((S_true - S_pred)**2 + (I_true - I_pred)**2 + (R_true - R_pred)**2)\n",
    "    physics_loss = tf.reduce_mean(eq1**2 + eq2**2 + eq3**2)\n",
    "    return data_loss + physics_loss\n",
    "\n",
    "# Compile and train the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "@tf.function\n",
    "def train_step(t, S_true, I_true, R_true):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = pinn_loss(t, S_true, I_true, R_true)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(tf.convert_to_tensor(t[:, None], dtype=tf.float32),\n",
    "                      tf.convert_to_tensor(S[:, None], dtype=tf.float32),\n",
    "                      tf.convert_to_tensor(I[:, None], dtype=tf.float32),\n",
    "                      tf.convert_to_tensor(R[:, None], dtype=tf.float32))\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
